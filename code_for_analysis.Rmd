---
title: "deliverable2"
output: html_document
---

# Loading dataset
```{r}
data = read.csv('/Users/Jerry/Desktop/tmdb-5000-movie-dataset/cleaned_tmdb.csv',
                stringsAsFactors = F)
```

# Analysis of overview
```{r}
library(dplyr)
library(ggplot2); library(ggthemes)
library(stringr)
```

```{r}
# Longest overview and Shortest overview
summary(str_count(string = data$overview,pattern = '\\S+'))
```

## overview length and ratings, revenue
```{r}
# length in words
cor(str_count(string = data$overview,pattern = '\\S+'),data$vote_average)
cor(str_count(string = data$overview,pattern = '\\S+'),data$revenue)
```

## look at the top 25 common words list after removing the stopwords
```{r}
freq_terms(text.var=data$overview,top=25,stopwords = Top200Words)
plot(freq_terms(text.var=data$overview,top=25,stopwords = Top200Words))
```

## Sentiment Analysis
```{r}
# create index column named 'id'
data$id = seq.int(nrow(data))
```

```{r}
# total number of positive and negative
data%>%
  group_by(id)%>%
  unnest_tokens(output = word, input = overview)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()

# visualization
data%>%
  group_by(id)%>%
  unnest_tokens(output = word, input = overview)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+geom_col()+theme_economist()+guides(fill=F)
```

## Proportion of Positive words in overviews
```{r}
data %>%
  select(id,overview)%>%
  group_by(id)%>%
  unnest_tokens(output=word,input=overview)%>%
  ungroup()%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  summarize(n = n())%>%
  mutate(proportion = n/sum(n))
```

```{r}
# relation between positivity/total and vote_average
data%>%
  group_by(id)%>%
  unnest_tokens(output = word, input = overview)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(id,vote_average)%>%
  summarize(positivity = sum(sentiment=='positive')/n())%>%
  ungroup()%>%
  summarize(correlation = cor(positivity,vote_average))
```

```{r}
# relation between positivity/total and revenue
data%>%
  group_by(id)%>%
  unnest_tokens(output = word, input = overview)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(id,revenue)%>%
  summarize(positivity = sum(sentiment=='positive')/n())%>%
  ungroup()%>%
  summarize(correlation = cor(positivity,revenue))
```

## nrc lexicon
```{r}
# examine the emotions expressed in the overviews
data%>%
  group_by(id)%>%
  unnest_tokens(output = word, input = overview)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment)%>%
  count()

data%>%
  group_by(id)%>%
  unnest_tokens(output = word, input = overview)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n),y=n,fill=sentiment))+geom_col()+guides(fill=F)+coord_flip()+theme_wsj()
```

## Afinn Lexicon
```{r}
# examine the sentiment of all reviews.
data %>%
  select(id,overview)%>%
  group_by(id)%>%
  unnest_tokens(output=word,input=overview)%>%
  inner_join(get_sentiments('afinn'))%>%
  summarize(reviewSentiment = mean(score))%>%
  ungroup()%>%
  summarize(min=min(reviewSentiment),max=max(reviewSentiment),median=median(reviewSentiment),mean=mean(reviewSentiment))

data %>%
  select(id,overview)%>%
  group_by(id)%>%
  unnest_tokens(output=word,input=overview)%>%
  inner_join(get_sentiments('afinn'))%>%
  summarize(reviewSentiment = mean(score))%>%
  ungroup()%>%
  ggplot(aes(x=reviewSentiment,fill=reviewSentiment>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+scale_fill_manual(values=c('tomato','seagreen'))+
  guides(fill=F)+
  theme_wsj()
```

## Wordcloud
```{r}
library(wordcloud)
wordcloudData = 
  data%>%
  group_by(id)%>%
  unnest_tokens(output=word,input=overview)%>%
  anti_join(stop_words)%>%
  group_by(word)%>%
  summarize(freq = n())%>%
  arrange(desc(freq))%>%
  ungroup()%>%
  data.frame()

set.seed(617)
wordcloud(words = wordcloudData$word,wordcloudData$freq,scale=c(2,0.5),max.words = 100,colors=brewer.pal(9,"Spectral"))
```

```{r}
# Comparison Cloud
library(tidyr)
wordcloudData = 
  data%>%
  group_by(id)%>%
  unnest_tokens(output=word,input=overview)%>%
  anti_join(stop_words)%>%
  inner_join(get_sentiments('bing'))%>%
  ungroup()%>%
  count(sentiment,word,sort=T)%>%
  spread(key=sentiment,value = n,fill=0)%>%
  data.frame()
rownames(wordcloudData) = wordcloudData[,'word']
wordcloudData = wordcloudData[,c('positive','negative')]
set.seed(617)
comparison.cloud(term.matrix = wordcloudData,scale = c(2,0.5),max.words = 200, rot.per=0)

```


# Analysis of genre and budget
## I want to find how many movies are there in each genre. Firstï¼Œparse the column 'genres' and get rid of the square brackets.Seperate it so each row only contains one genre. 
```{r}
data2 = read.csv('/Users/Jerry/Desktop/tmdb-5000-movie-dataset/cleaned_tmdb.csv',
                stringsAsFactors = F)
library(dplyr)
library(gsubfn)
library(tidyr)
genres=gsub("\\[|\\]", "\\\\", data2$genres) 
data2=cbind(data2,genres)
data2=data2[,-c(2)]
data2=separate_rows(data2,genres,sep = "[^[:alnum:].]+", convert = FALSE)
summary(data2$genres)
```

## Observe how many movies there are under some major genres
```{r}
as.character(data2$genres)
class(data2$genres)
str(data2$genres)
summary(data2$genres)
sum(data2$genres=="Action",na.rm=FALSE)
sum(data2$genres=="Adventure",na.rm=FALSE)
sum(data2$genres=="Fantasy",na.rm=FALSE)
sum(data2$genres=="Science",na.rm=FALSE)
sum(data2$genres=="Fiction",na.rm=FALSE)
sum(data2$genres=="Crime",na.rm=FALSE)
sum(data2$genres=="Drama",na.rm=FALSE)
sum(data2$genres=="Thriller",na.rm=FALSE)
sum(data2$genres=="Animation",na.rm=FALSE)
sum(data2$genres=="Western",na.rm=FALSE)
sum(data2$genres=="Family",na.rm=FALSE)
sum(data2$genres=="Mystery",na.rm=FALSE)
sum(data2$genres=="Comedy",na.rm=FALSE)
sum(data2$genres=="Romance",na.rm=FALSE)
sum(data2$genres=="Horror",na.rm=FALSE)
sum(data2$genres=="",na.rm=FALSE)
```

## Seperate rows so that each row contains one genre name, remove empty cells and some small genres.
```{r}
Action=c("Action")
Adventure=c("Adventure")
Fantasy=c("Fantasy")
Science=c("Science")
Fiction=c("Fiction")
Crime=c("Crime")
Drama=c("Drama")
Thriller=c("Thriller")
Animation=c("Animation")
Western=c("Western")
Family=c("Family")
Mystery=c("Mystery")
Comedy=c("Comedy")
Romance=c("Romance")
Horror=c("Horror")
data2$type=
ifelse(data2$genres %in% Action, "Action", 
ifelse(data2$genres %in% Adventure, "Adventure", 
ifelse(data2$genres %in% Fantasy, "Fantasy", 
ifelse(data2$genres %in% Science, "Science",
ifelse(data2$genres %in% Fiction, 'Fiction',
ifelse(data2$genres %in% Crime, 'Crime',      
ifelse(data2$genres %in% Drama, 'Drama',
ifelse(data2$genres %in% Thriller, 'Thriller',
ifelse(data2$genres %in% Animation, 'Animation',
ifelse(data2$genres %in% Western, 'Western',
ifelse(data2$genres %in% Family, 'Family',
ifelse(data2$genres %in% Mystery, 'Mystery',
ifelse(data2$genres %in% Comedy, 'Comedy',
ifelse(data2$genres %in% Romance, 'Romance',
ifelse(data2$genres %in% Horror, 'Horror',
"NA")))))))))))))))
summary(data2$type)
data2=data2[which(data2$type!="NA"),]
head(data2)
data2 = subset(data2, select = -c(type) )
# Now we have one genre in each row.
```

## Convert genres from character to factor datatype. 
```{r}
library(dplyr)
data2 <- mutate_if(data2, is.character, as.factor)
```

## Genre Analysis
```{r}
install.packages('NLP')
```
## Genre Distribution ___number of movies per genre
```{r}
library(tm)
library(dplyr)
library(ggplot2)
library(wordcloud)
genre <- Corpus(VectorSource(data2$genres))
genre_dtm <- DocumentTermMatrix(genre)
genre_freq <- colSums(as.matrix(genre_dtm))
freq <- sort(colSums(as.matrix(genre_dtm)), decreasing=TRUE) 
genre_wf <- data.frame(word=names(genre_freq), freq=genre_freq)

ggplot(genre_wf, aes(x=reorder(word,-freq), y=freq))+ 
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle=90),plot.title=element_text(color="Black",face="bold"),legend.position="none")+
  #theme(axis.text.x=element_text(angle=45, hjust=1))+
  ggtitle("Distribution of Movies by Genre")+
  xlab("Genre")+
  ylab("No of Movies")
```

## sentiment analysis of movie genre(wordcount)
```{r}
set.seed(1)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(genre_wf$word,genre_wf$freq,random.order=TRUE,
          rot.per=.15, colors=pal2,scale=c(4,.9))

```


## Distribution of factors among genres;
```{r}
ggplot(data2,aes(y=revenue/1000000,fill=genres))+geom_boxplot() 
ggplot(data2,aes(y=budget/1000000,fill=genres))+geom_boxplot() 
ggplot(data2,aes(y=profit,fill=genres))+geom_boxplot() 
ggplot(data2,aes(y=vote_average,fill=genres))+geom_boxplot() 
ggplot(data2,aes(y=vote_count,fill=genres))+geom_boxplot() 
ggplot(data2,aes(y=popularity,fill=genres))+geom_boxplot() 
ggplot(data2,aes(y=runtime,fill=genres))+geom_boxplot() 
```


## Observe the correlation among important movie factors
```{r}
library(corrgram)
corrgram_data <- data2 %>% 
  dplyr::select(., budget,popularity, revenue,runtime, vote_average,vote_count,profit)

corrgram(corrgram_data)
```

## k-mean clustering
```{r}
library(ggplot2)
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(caret)
set.seed(123)
#Generate movie clusters and plot
mydataCluster <- kmeans(na.omit(scale(data2[, c("budget","popularity", "revenue","runtime", "vote_average","vote_count","profit")])), 2, nstart = 20)
data2$cluster <- as.factor(mydataCluster$cluster)
ggplot(data2, aes(revenue, vote_average, color = data2$cluster)) + geom_point()+scale_colour_manual(values=c("green", "blue","orange","purple","red")) + xlab("revenue") + ylab("vote_average")
```


# Analysis of runtime, tagline, and keywords
```{r}
data3 = read.csv('/Users/Jerry/Desktop/tmdb-5000-movie-dataset/cleaned_tmdb.csv',
                stringsAsFactors = F)
```

## Runtime
```{r}
#Explore correlation between runtime and vote_average & profit
cor(data3$runtime, data3$vote_average)
cor(data3$runtime, data3$revenue)

plot(data3$runtime, data3$vote_average)
plot(data3$runtime, data3$revenue)
```

##Text mining on tagline
```{r}
#Average number of characters and words in the tagline
library(stringr)

#Common words used in taglines
library(qdap)
freq_terms(text.var = data3$tagline,top = 25, stopwords = Top200Words)
plot(freq_terms(text.var=data3$tagline,top=25,stopwords = Top200Words))
```

```{r}
#Common words used in taglines
library(qdap)
freq_terms(text.var = data3$tagline,top = 25, stopwords = Top200Words)
plot(freq_terms(text.var=data3$tagline,top=25,stopwords = Top200Words))
```

```{r}
#Sentiment Analysis
library(dplyr); library(tidytext)
```

```{r}
#Positive and negtive words in taglines
data3%>%
  unnest_tokens(output = word, input = tagline)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()
```

```{r}
#Sentiment and vote_average
data3 %>%
  select(tagline,vote_average)%>%
  unnest_tokens(output=word,input=tagline)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(vote_average,sentiment)%>%
  summarize(n = n())%>%
  mutate(proportion = n/sum(n))%>%
  ggplot(aes(x=vote_average,y=proportion,fill=sentiment))+geom_col()
```

```{r}
#Correlation between positive words and vote_average & profit
data3%>%
  unnest_tokens(output = word, input = tagline)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(word,vote_average)%>%
  summarize(positivity = sum(sentiment=='positive')/n())%>%
  ungroup()%>%
  summarize(correlation = cor(positivity,vote_average))

data3%>%
  unnest_tokens(output = word, input = tagline)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(word,profit)%>%
  summarize(positivity = sum(sentiment=='positive')/n())%>%
  ungroup()%>%
  summarize(correlation = cor(positivity,profit))
```

```{r}
#Emotions in taglines
data3%>%
  unnest_tokens(output = word, input = tagline)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n),y=n,fill=sentiment))+geom_col()+guides(fill=F)+coord_flip()
```

```{r}
#Vote_average based on tagline emotion
data3%>%
  unnest_tokens(output = word, input = tagline)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment,vote_average)%>%
  count()%>%
  summarize(n = mean(n))%>%
  ungroup()%>%
  ggplot(aes(x=vote_average,y=n,fill=vote_average))+
  geom_line()+
  facet_wrap(~sentiment)+
  guides(fill=F)+coord_flip()
```

```{r}
#Wordcloud
library(tidyr)
library(wordcloud)
wordcloudData = 
  data3%>%
  unnest_tokens(output=word,input=tagline)%>%
  anti_join(stop_words)%>%
  inner_join(get_sentiments('bing'))%>%
  count(sentiment,word,sort=T)%>%
  spread(key=sentiment,value = n,fill=0)%>%
  data.frame()
rownames(wordcloudData) = wordcloudData[,'word']
wordcloudData = wordcloudData[,c('positive','negative')]
set.seed(617)
comparison.cloud(term.matrix = wordcloudData,scale = c(2,0.7),max.words = 100, rot.per=0)
```

## Keywords
```{r}
#Clean out keywords variable from JSON object
library(tidyverse)
data_raw = read_csv('/Users/Jerry/Desktop/tmdb-5000-movie-dataset/tmdb_5000_movies.csv', guess_max = 3000)

library(stringr)
library(jsonlite)
keywords <- data_raw %>%    
  filter(nchar(keywords)>2) %>%     # fiter out blank keywords field
  mutate(                           # create a new field 
    js = lapply(keywords, fromJSON) #   containing a LIST of keyword and value pairs
  ) %>%                             #   called id and name
  unnest(js) %>%                    # turn each keyword/value pairs in the LIST into a row
  select(id, title,vote_average,revenue, keyword=name)   # select the columns we want

str(keywords)
```

```{r}
# calculate frequencies
tab <- table(keywords$keyword)
# sort
tab_s <- sort(tab)
# extract 10 most frequent nationalities
top15 <- tail(names(tab_s), 15)
# subset of data frame
d_s <- subset(keywords, keyword %in% top15)
# order factor levels
d_s$keyword <- factor(d_s$keyword, levels = rev(top15))

# plot
library(ggplot2)
ggplot(d_s, aes(y = revenue, fill = keyword)) + geom_boxplot()
ggplot(d_s, aes(y = vote_average, fill = keyword)) + geom_boxplot()
```

```{r}
#Check median values for the best % worst vote_average movie keywords
median(d_s$vote_average[d_s$keyword == "based on novel"])
median(d_s$vote_average[d_s$keyword == "biography"])
median(d_s$vote_average[d_s$keyword == "teenager"])
```

```{r}
#Check median values for the highest % lowest revenue movie keywords
median(d_s$revenue[d_s$keyword == "duringcreditsstinger"])
median(d_s$revenue[d_s$keyword == "aftercreditsstinger"])
median(d_s$revenue[d_s$keyword == "dystopia"])
median(d_s$revenue[d_s$keyword == "independent film"])
```

## Text mining on keywords
```{r}
#Average number of characters and words in the keywords
library(stringr)
data3$keywords = as.character(data3$keywords)
mean_char = mean(nchar(data3$keywords))
mean_char #121.8944
mean_words=mean(str_count(string = data3$keywords,pattern = '\\S+'))
mean_words #5.718834
```

```{r}
#Longest and shortest keywords
summary(str_count(string = data3$keywords,pattern = '\\S+')) 

shortest_keywords = which.min(str_count(string = data3$keywords,pattern = '\\S+'))
data3$keywords[shortest_keywords]

longest_keywords = which.max(str_count(string = data3$keywords,pattern = '\\S+'));
data3$keywords[longest_keywords]
```

```{r}
# Correlation between keywords length and popularity,profit,budget,revenue
cor(nchar(data3$keywords), data3$popularity) 
cor(nchar(data3$keywords), data3$profit) 
cor(nchar(data3$keywords), data3$budget) 
cor(nchar(data3$keywords), data3$revenue) 

cor((str_count(string = data3$keywords,pattern = '\\S+')), data3$popularity) 
cor((str_count(string = data3$keywords,pattern = '\\S+')), data3$profit) 
cor((str_count(string = data3$keywords,pattern = '\\S+')), data3$budget) 
cor((str_count(string = data3$keywords,pattern = '\\S+')), data3$revenue) 
cor((str_count(string = data3$keywords,pattern = '\\S+')), data3$vote_average) 
```

```{r}
#Common words used in keywords
library(qdap)
freq_terms(text.var = data3$keywords,top = 25, stopwords = Top200Words)
plot(freq_terms(text.var=data3$keywords,top=25,stopwords = Top200Words))
```

```{r}
#Sentiment Analysis
library(dplyr); library(tidytext)
```

```{r}
# Positive and negtive words in keywords
data3%>%
  unnest_tokens(output = word, input = keywords)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()
```

```{r}
# Correlation between positive words and popularity & revenue
data3%>%
  unnest_tokens(output = word, input = keywords)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(word,popularity)%>%
  summarize(positivity = sum(sentiment=='positive')/n())%>%
  ungroup()%>%
  summarize(correlation = cor(positivity,popularity))

data3%>%
  unnest_tokens(output = word, input = keywords)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(word,revenue)%>%
  summarize(positivity = sum(sentiment=='positive')/n())%>%
  ungroup()%>%
  summarize(correlation = cor(positivity,revenue))
```

```{r}
#Emotions in keywords
data3%>%
  unnest_tokens(output = word, input = keywords)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n),y=n,fill=sentiment))+geom_col()+guides(fill=F)+coord_flip()
```

```{r}
# Revenue based on keywords emotion
data3%>%
  unnest_tokens(output = word, input = keywords)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment,revenue)%>%
  count()%>%
  summarize(n = mean(n))%>%
  ungroup()%>%
  ggplot(aes(x=revenue,y=n,fill=revenue))+
  geom_line()+
  facet_wrap(~sentiment)+
  guides(fill=F)+coord_flip()
```

```{r}
#Profit and keywords emotion
data3%>%
  unnest_tokens(output = word, input = keywords)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment,revenue)%>%
  count()%>%
  summarize(n = mean(n))%>%
  ungroup()%>%
  ggplot(aes(x=revenue,y=n,fill=revenue))+
  geom_line()+
  facet_wrap(~sentiment)+
  guides(fill=F)
```

```{r}
# Correlation between emotion expressed and popularity
data3%>%
  unnest_tokens(output = word, input = keywords)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment, popularity)%>%
  count()%>%
  ungroup()%>%
  group_by(sentiment)%>%
  summarize(correlation = cor(n,popularity))

data3%>%
   unnest_tokens(output = word, input = keywords)%>%
   inner_join(get_sentiments('nrc'))%>%
   group_by(sentiment, revenue)%>%
   count()%>%
   ungroup()%>%
   group_by(sentiment)%>%
   summarize(correlation = cor(n,revenue))
```

```{r}
# Correlation between emotion expressed and revenue
data3%>%
  unnest_tokens(output = word, input = keywords)%>%
  inner_join(get_sentiments('nrc'))%>%
  group_by(sentiment,revenue)%>%
  count()%>%
  ungroup()%>%
  group_by(sentiment)%>%
  ggplot(aes(x=revenue,y=n))+geom_point()+facet_wrap(~sentiment)+geom_smooth(method='lm',se=F)
```

```{r}
#Wordcloud
library(tidyr)
library(wordcloud)
wordcloudData = 
  data3%>%
  unnest_tokens(output=word,input=keywords)%>%
  anti_join(stop_words)%>%
  inner_join(get_sentiments('bing'))%>%
  count(sentiment,word,sort=T)%>%
  spread(key=sentiment,value = n,fill=0)%>%
  data.frame()

rownames(wordcloudData) = wordcloudData[,'word']
wordcloudData = wordcloudData[,c('positive','negative')]
set.seed(617)
comparison.cloud(term.matrix = wordcloudData,scale = c(2,0.7),max.words = 100, rot.per=0)
```

## Explore correlation between popularity and budget,revenue,profit,vote_average
```{r}
cor(data3$popularity,data3$revenue) 
cor(data3$popularity,data3$budget) 
cor(data3$popularity,data3$profit) 
cor(data3$popularity,data3$vote_average) 

plot(data3$popularity,data3$revenue)
plot(data3$popularity,data3$vote_average)
```

## Top popularity movies (top 20%)
```{r}
data_top_popularity = subset(data3, popularity > quantile(popularity, prob = 1 - 20/100))
data_top_revenue = subset(data3, revenue > quantile(profit, prob = 1 - 20/100))
data_top_popularity
data_top_revenue
```

## Check budget difference for top popularity and top revenue
```{r}
popularity_com = cbind(mean(data_top_popularity$budget), mean(data$budget))
barplot(popularity_com, names.arg=c('top_vote_popularity_average','budget_average'))

revenue_com = cbind(mean(data_top_revenue$budget), mean(data$budget))
barplot(revenue_com, names.arg=c('top_revenue_budget_average','budget_average'))
```


# Production Companies & Release Date
```{r}
library(ggplot2)
library(lubridate)
library(mice)
library(cluster)
library(psych)
library(dplyr)
library(tidyr)
library(RColorBrewer)
library(plyr)

data4 = read.csv('/Users/Jerry/Desktop/tmdb-5000-movie-dataset/cleaned_tmdb.csv',
                stringsAsFactors = F)
```

## Clustering
```{r}
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(caret)
```

```{r}
data_cluster = scale(data4[, c("budget","popularity", "revenue","runtime", "vote_average","vote_count","profit")])
```

```{r}
# Determination of segmentations number
within_ss = sapply(1:10,FUN = function(x) kmeans(x = data_cluster,centers = x)$tot.withinss)
ggplot(data=data.frame(cluster = 1:10,within_ss),aes(x=cluster,y=within_ss))+
  geom_line(col='steelblue',size=1.2)+
  geom_point()+
  scale_x_continuous(breaks=seq(1,10,1))

ratio_ss = sapply(1:10,FUN = function(x) {km = kmeans(x = data_cluster,centers = x)
km$betweenss/km$totss} )
ggplot(data=data.frame(cluster = 1:10,ratio_ss),aes(x=cluster,y=ratio_ss))+
  geom_line(col='steelblue',size=1.2)+
  geom_point()+
  scale_x_continuous(breaks=seq(1,10,1))

silhoette_width = sapply(2:10,FUN = function(x) pam(x = data_cluster,k = x)$silinfo$avg.width)
ggplot(data=data.frame(cluster = 2:10,silhoette_width),aes(x=cluster,y=silhoette_width))+
  geom_line(col='steelblue',size=1.2)+
  geom_point()+
  scale_x_continuous(breaks=seq(2,10,1))
```

```{r}
# K-mean clustering
km = kmeans(na.omit(data_cluster), 2, nstart = 20)
k_segments = as.factor(km$cluster)
table(k_segments)
data4 = cbind(data4,k_segments)

ggplot(data4, aes(revenue, vote_average, color = k_segments)) + 
  geom_point()+scale_colour_manual(values=c("green","red")) + 
  xlab("revenue") + ylab("vote_average")
```

## Release Month and Release Year Analysis
```{r}
# Add columns of release year and month
data4$release_date = as.Date(data4$release_date)
data4$releaseyear = year(data4$release_date)
data4$releasemonth = month(data4$release_date)
```

```{r}
# Plot Avarage Year Revenue and Month Revenue
mean_month = aggregate(data4[, c(11,17)], list(data4$releasemonth), mean)

ggplot(mean_month, aes(x = Group.1, y = revenue)) + 
  geom_bar(stat = "identity") +
  xlab("Month") + ylab("Revenue")

ggplot(mean_month, aes(x = Group.1, y = vote_average)) + 
  geom_line(stat = "identity") +
  xlab("Month") + ylab("Vote_Average")

mean_year = aggregate(data4[, c(11,17)], list(data4$releaseyear), mean)

ggplot(mean_year, aes(x = Group.1, y = revenue)) + 
  geom_bar(stat = "identity") +
  xlab("Year") + ylab("Revenue")

ggplot(mean_year, aes(x = Group.1, y = vote_average)) + 
  geom_line(stat = "identity") +
  xlab("Year") + ylab("Vote_Average")
```

## Production Coompanies Analysis

```{r}
library(tidyverse)
data_raw = read_csv('/Users/Jerry/Desktop/tmdb-5000-movie-dataset/tmdb_5000_movies.csv', guess_max = 3000)

library(stringr)
library(jsonlite)

production_com <- data_raw %>%    
  filter(nchar(production_companies)>2) %>%
  mutate(                            
    js = lapply(production_companies, fromJSON)
  ) %>%                             
  unnest(js) %>%                    
  select(id, title, vote_average,revenue, production_companies=name)  

str(production_com)
```

```{r}
# calculate frequencies
t <- table(production_com$production_companies)
# sort
sort_t <- sort(t)
# extract 10 most frequent nationalities
p_top15 <- tail(names(sort_t), 15)
# subset of data frame   
p_s <- subset(production_com, production_companies %in% p_top15)
# order factor levels
p_s$production_companies <- factor(p_s$production_companies, levels = rev(p_top15))
```

```{r}
# Boxplot of Production Companies
library(ggplot2)
ggplot(p_s, aes(y = revenue, fill = production_companies)) + geom_boxplot()
ggplot(p_s, aes(y = vote_average, fill = production_companies)) + geom_boxplot()
```

```{r}
# Number of Movies per Production Companies
plot(table(p_s$production_companies))
```

```{r}
# Relationship between Vote Average and Revenue depends on Production Companies
library(plotly)
plot_ly(p_s, x = ~vote_average, y = ~revenue, mode = "markers", marker=list( size=3 , opacity=0.5), color = ~production_companies,colors = rainbow(15))
```

##Production Countries
```{r}
production_cty <- data_raw %>%    
  filter(nchar(production_countries)>2) %>%     
  mutate(                          
    js = lapply(production_countries, fromJSON) 
  ) %>%                             
  unnest(js) %>%                    
  select(id, title, vote_average,revenue, production_countries=name)  
```

```{r}
# Calculate Frequencies
t <- table(production_cty$production_countries)
# sort
sort_t <- sort(t)
# extract 10 most frequent nationalities
p_top15 <- tail(names(sort_t), 15)
# subset of data frame
p_s <- subset(production_cty, production_countries %in% p_top15)
# order factor levels
p_s$production_countries <- factor(p_s$production_countries, levels = rev(p_top15))
```

```{r}
# Boxplot of Production Companies
library(ggplot2)
ggplot(p_s, aes(y = revenue, fill = production_countries)) + geom_boxplot()
ggplot(p_s, aes(y = vote_average, fill = production_countries)) + geom_boxplot()
```

```{r}
# Number of Movies per Production Companies
plot(table(p_s$production_countries))
```

```{r}
# Relationship between Vote Average and Revenue depends on Production Companies
library(plotly)
plot_ly(p_s, x = ~vote_average, y = ~revenue, mode = "markers", marker=list( size=3 , opacity=0.5), color = ~production_countries,colors = rainbow(15))
```





















